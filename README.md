# ğŸ¤ğŸ¤– Alpha Voice Assistant

An advanced AI-powered voice assistant built with **DeepSeek AI**, **Speech Recognition**, and **Text-to-Speech** capabilities. Features real-time voice interaction, intelligent error handling, and a modern web interface.

## âœ¨ Features

- ğŸ¤ **Multiple Input Methods**: Text, audio file upload, live microphone recording with start/stop controls
- ğŸ§  **AI-Powered Responses**: Using DeepSeek-V3 via OpenRouter API with intelligent fallback
- ğŸ”Š **Text-to-Speech**: Adjustable speech speed and voice output using pyttsx3
- âš™ï¸ **Customizable Settings**: AI creativity level, response length, and voice speed controls
- ğŸ¯ **Quick Actions**: Pre-defined conversation starters and common interactions
- ğŸ“± **Modern UI**: Clean, responsive Gradio interface with custom CSS styling
- ğŸ”„ **Smart Fallback**: Automatic demo mode when API is unavailable
- ğŸ›¡ï¸ **Error Handling**: Robust error handling with user-friendly messages
- ğŸ™ï¸ **Background Recording**: Non-blocking audio recording with threading
- ğŸ“¡ **API Validation**: Automatic API key testing and status reporting

## ğŸ› ï¸ Tech Stack

### Frontend & UI
- **[Gradio](https://gradio.app/)** - Modern web interface framework
- **Custom CSS** - Enhanced styling with gradients and animations
- **HTML/Markdown** - Rich text formatting and layout

### AI & Language Models
- **[OpenRouter API](https://openrouter.ai/)** - AI model routing and access
- **[DeepSeek-V3](https://deepseek.com/)** - Advanced language model (deepseek-chat-v3-0324:free)
- **JSON** - Data serialization for API communication

### Audio Processing
- **[SpeechRecognition](https://pypi.org/project/SpeechRecognition/)** - Speech-to-text conversion
- **[Google Speech Recognition API](https://cloud.google.com/speech-to-text)** - Cloud-based transcription
- **[pyttsx3](https://pypi.org/project/pyttsx3/)** - Text-to-speech synthesis
- **[PyAudio](https://pypi.org/project/PyAudio/)** - Real-time audio I/O

### Backend & Core
- **[Python 3.11+](https://python.org/)** - Core programming language
- **[Requests](https://requests.readthedocs.io/)** - HTTP client for API calls
- **[Threading](https://docs.python.org/3/library/threading.html)** - Concurrent audio processing
- **[OS/Environment Variables](https://docs.python.org/3/library/os.html)** - Configuration management
- **[Warnings](https://docs.python.org/3/library/warnings.html)** - Error suppression and handling
- **[Time](https://docs.python.org/3/library/time.html)** - Timing and delays
- **[Random](https://docs.python.org/3/library/random.html)** - Demo response generation

### Development & Deployment
- **[Git](https://git-scm.com/)** - Version control
- **[GitHub](https://github.com/)** - Repository hosting
- **[pip](https://pip.pypa.io/)** - Package management
- **[requirements.txt](https://pip.pypa.io/en/stable/user_guide/#requirements-files)** - Dependency specification

### Architecture Features
- **Event-driven UI** - Gradio component interactions
- **State management** - Chat history and session persistence
- **Error boundaries** - Graceful degradation and fallback modes
- **Responsive design** - Adaptive layout for different screen sizes
- **Background processing** - Non-blocking audio operations
- **API abstraction** - Clean separation of AI service logic

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11 or higher
- Microphone access (for voice input)
- Internet connection (for AI responses)
- OpenRouter API key (optional - has demo mode)

### Local Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/BSRohit20/alpha-voice-bot.git
   cd alpha-voice-bot
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up your API key**
   - Get your OpenRouter API key from [OpenRouter](https://openrouter.ai/keys)
   - Update the `API_KEY` variable in `voice_bot.py` or set environment variable:
     ```bash
     # Windows PowerShell
     $env:OPENROUTER_API_KEY="your_api_key_here"
     
     # Windows CMD
     set OPENROUTER_API_KEY=your_api_key_here
     
     # Linux/Mac
     export OPENROUTER_API_KEY=your_api_key_here
     ```

4. **Run the application**
   ```bash
   python voice_bot.py
   ```

5. **Open in browser** - The app will automatically open at `http://localhost:7861`

## ğŸŒ Deployment

### Local Development (Full Features)

1. **Clone the repository**
   ```bash
   git clone https://github.com/BSRohit20/alpha-voice-bot.git
   cd alpha-voice-bot
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up your API key**
   - Get your OpenRouter API key from [OpenRouter](https://openrouter.ai/keys)
   - Set environment variable:
     ```bash
     # Windows
     set OPENROUTER_API_KEY=your_api_key_here
     
     # Linux/Mac
     export OPENROUTER_API_KEY=your_api_key_here
     ```

4. **Run the application**
   ```bash
   python voice_bot.py
   ```

### Cloud Deployment

> **Note**: For cloud deployment (Hugging Face Spaces), some microphone features may be limited due to platform constraints.

## ğŸ›ï¸ Usage Guide

### ğŸ’¬ Text Chat
- Type your message in the large text area
- Click "ğŸ“¤ Send" button or press Enter to get AI responses
- Use the "ğŸ—‘ï¸ Clear Chat" button to reset conversation history

### ğŸ¤ Voice Input Options

#### Quick Voice (Instant)
- Click "âš¡ Quick Voice" for immediate 5-second voice capture
- Best for short commands or questions
- Automatically processes and responds

#### Controlled Recording
- Click "ğŸ¤ Start Recording" to begin voice capture
- Speak your message (no time limit)
- Click "â¹ï¸ Stop Recording" when finished
- Perfect for longer conversations or detailed questions

#### Audio File Upload
- Click "ğŸ™ï¸ Upload Audio File" area
- Upload WAV, MP3, or M4A files
- Supports various audio formats and quality levels

### âš™ï¸ Settings & Controls

#### AI Creativity Level (ğŸ§ )
- **0.0-0.3**: Focused, factual responses
- **0.4-0.7**: Balanced creativity and accuracy
- **0.8-1.0**: Creative, diverse responses

#### Speech Speed (ğŸ”Š)
- **0.5x**: Slow, clear speech
- **1.0x**: Normal speed (default)
- **2.0x**: Fast speech

#### Response Length (ğŸ“)
- **100-500 tokens**: Short, concise answers
- **500-1024 tokens**: Detailed responses (default)
- **1024-2000 tokens**: Comprehensive, in-depth answers

### ğŸ¯ Quick Actions
- **ğŸ‘‹ Say Hello**: Start a friendly conversation
- **ğŸ˜„ Tell Joke**: Get a random joke from the AI
- **â“ Get Help**: Learn about the bot's capabilities
- **â„¹ï¸ Bot Info**: Get information about the assistant

## ğŸ—ï¸ Project Architecture

### ğŸ“ File Structure
```
alpha-voice-bot/
â”œâ”€â”€ voice_bot.py           # Main application file
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # Project documentation
â”œâ”€â”€ .gitignore           # Git ignore rules
â””â”€â”€ assets/              # Additional resources (if any)
```

### ğŸ”§ Core Components

#### 1. Audio Processing Pipeline
```python
Microphone â†’ SpeechRecognition â†’ Google API â†’ Text
Audio File â†’ SpeechRecognition â†’ Google API â†’ Text
Text â†’ pyttsx3 â†’ Audio Output
```

#### 2. AI Processing Flow
```python
User Input â†’ Message History â†’ OpenRouter API â†’ DeepSeek Model â†’ Response
API Failure â†’ Fallback â†’ Demo Mode â†’ Offline Responses
```

#### 3. UI Component Hierarchy
```python
Gradio Blocks
â”œâ”€â”€ Header (Gradient Design)
â”œâ”€â”€ Main Row
â”‚   â”œâ”€â”€ Chat Column
â”‚   â”‚   â”œâ”€â”€ Chatbot Interface
â”‚   â”‚   â”œâ”€â”€ Text Input
â”‚   â”‚   â”œâ”€â”€ Send/Clear Buttons
â”‚   â”‚   â””â”€â”€ Audio Controls
â”‚   â””â”€â”€ Control Column
â”‚       â”œâ”€â”€ Settings Panel
â”‚       â””â”€â”€ Quick Actions
â””â”€â”€ Event Handlers
```

## ğŸ› ï¸ Technical Implementation

### ğŸ”Œ API Integration
- **OpenRouter Endpoint**: `https://openrouter.ai/api/v1/chat/completions`
- **Model**: `deepseek/deepseek-chat-v3-0324:free`
- **Authentication**: Bearer token via API key
- **Error Handling**: Automatic fallback to demo mode

### ğŸµ Audio Processing
- **Input Formats**: WAV, MP3, M4A, FLAC
- **Speech Recognition**: Google Web Speech API
- **Voice Synthesis**: System TTS engines via pyttsx3
- **Threading**: Background processing for non-blocking UI

### ğŸ¨ UI Technologies
- **Framework**: Gradio 4.x
- **Styling**: Custom CSS with gradient themes
- **Theme**: Soft theme with custom overrides
- **Responsive**: Adaptive layout for different screen sizes

### ğŸ’¾ State Management
- **Chat History**: Gradio State component
- **Session Persistence**: In-memory during runtime
- **Recording State**: Global variables with thread safety
- **Configuration**: Runtime parameter adjustment

## ğŸ”§ Configuration Options

### Environment Variables
```bash
OPENROUTER_API_KEY=your_api_key_here    # Required for AI features
GRADIO_SERVER_PORT=7861                 # Custom port (optional)
GRADIO_ANALYTICS_ENABLED=False          # Disable analytics
```

### Runtime Configuration
```python
# In voice_bot.py
API_KEY = "your_key_here"               # Direct API key setting
MODEL = "deepseek/deepseek-chat-v3-0324:free"  # AI model selection
```

### Server Configuration
```python
demo.launch(
    server_name="127.0.0.1",           # Local access only
    server_port=7861,                  # Custom port
    inbrowser=True,                    # Auto-open browser
    share=False                        # Disable public sharing
)
```

## ğŸ”§ Configuration

### Environment Variables

- `OPENROUTER_API_KEY`: Your OpenRouter API key (required for AI responses)

### Customization

You can modify these settings in `voice_bot.py`:
- Default AI model
- UI colors and styling
- Voice recognition parameters
- Response templates

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request


## ğŸ“ License

This project is open source and available under the [MIT License](LICENSE).

## ğŸ†˜ Support

If you encounter any issues:
1. Check that your API key is properly set
2. Ensure all dependencies are installed
3. Try the offline demo mode first
4. Open an issue on GitHub with error details

## ğŸ™ Acknowledgments

- **DeepSeek AI** for the language model
- **OpenRouter** for API access
- **Gradio** for the web interface
- **Google** for speech recognition services

---

**ğŸ‰ Enjoy chatting with your AI voice assistant!**
